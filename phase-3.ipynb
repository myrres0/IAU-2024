{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3f6786e569db31e9"
      },
      "source": [
        "# Phase 2 - Data preprocessing\n",
        "### Authors: Karolina Skrypova(50%), Oleh Fedunchyk(50%)"
      ],
      "id": "3f6786e569db31e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrWMBMRvqPBF"
      },
      "source": [
        "## Importing libraries"
      ],
      "id": "CrWMBMRvqPBF"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dmZatvBFp9Cs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "id": "dmZatvBFp9Cs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbwFgD6-qeoa"
      },
      "source": [
        "## Loading the data"
      ],
      "id": "LbwFgD6-qeoa"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pXBppNtMq0MA"
      },
      "outputs": [],
      "source": [
        "connections_data = pd.read_csv('https://raw.githubusercontent.com/myrres0/IAU-2024/main/dataset-120/connections.csv', sep='\\t')\n",
        "processes_data = pd.read_csv('https://raw.githubusercontent.com/myrres0/IAU-2024/main/dataset-120/processes.csv', sep='\\t')"
      ],
      "id": "pXBppNtMq0MA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHXGKDikq3ZU"
      },
      "source": [
        "## Datasets for processing"
      ],
      "id": "FHXGKDikq3ZU"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kgU-dbnfAZHg"
      },
      "outputs": [],
      "source": [
        "merged_data = pd.merge(processes_data, connections_data)"
      ],
      "id": "kgU-dbnfAZHg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R2v3D5tXWNZ"
      },
      "source": [
        "### Data cleaning"
      ],
      "id": "2R2v3D5tXWNZ"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "pjrqBLtIV5Jf"
      },
      "outputs": [],
      "source": [
        "class OutlierRemover(TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_ = self.resolve_missing_values(X)\n",
        "        X_ = X.drop_duplicates()\n",
        "        return X_.apply(self.transform_outliers)\n",
        "\n",
        "    # we do not have NA values in our dataset, but let this step be in our pipeline\n",
        "    def resolve_missing_values(self, X):\n",
        "        return pd.DataFrame(self.imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "    # we have checked mrwa have no outliers so can also be proceeded by this function\n",
        "    def transform_outliers(self, column):\n",
        "      Q1 = column.quantile(0.25)\n",
        "      Q3 = column.quantile(0.75)\n",
        "      IQR = Q3 - Q1\n",
        "      lower_bound = Q1 - 1.5 * IQR\n",
        "      upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "      outliers = column[(column < lower_bound) | (column > upper_bound)]\n",
        "      cleaned_column = column.clip(lower=lower_bound, upper=upper_bound)\n",
        "\n",
        "      return cleaned_column"
      ],
      "id": "pjrqBLtIV5Jf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeRxnu9qXcTl"
      },
      "source": [
        "### Data transforming"
      ],
      "id": "jeRxnu9qXcTl"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YnA1pCXCWqFn"
      },
      "outputs": [],
      "source": [
        "class PowerTransformerGroup(TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.power_transformer = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.power_transformer.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return pd.DataFrame(self.power_transformer.transform(X), columns=X.columns)"
      ],
      "id": "YnA1pCXCWqFn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vFjmkt4XmpH"
      },
      "source": [
        "### Data scaling"
      ],
      "id": "8vFjmkt4XmpH"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gI5iRtKkW9vB"
      },
      "outputs": [],
      "source": [
        "class StandardScalerGroup(TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.standard_scaler = StandardScaler()\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.standard_scaler.fit(X)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return pd.DataFrame(self.standard_scaler.transform(X), columns=X.columns)"
      ],
      "id": "gI5iRtKkW9vB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3f7dnjlXu-e"
      },
      "source": [
        "### Pipeline"
      ],
      "id": "o3f7dnjlXu-e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlwHdGexpVGk"
      },
      "source": [
        "Our constants:"
      ],
      "id": "hlwHdGexpVGk"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Nyhf336IYBBH"
      },
      "outputs": [],
      "source": [
        "selected_attributes = [\n",
        "    \"mwra\",\n",
        "    \"p.android.externalstorage\",\n",
        "    \"p.android.settings\",\n",
        "    \"p.android.gm\",\n",
        "    \"p.system\",\n",
        "    \"p.android.packageinstaller\",\n",
        "    \"c.android.gm\",\n",
        "    \"c.android.youtube\",\n",
        "    \"p.android.chrome\",\n",
        "    \"c.android.chrome\"\n",
        "]"
      ],
      "id": "Nyhf336IYBBH"
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_df(df):\n",
        "  mwra = df['mwra']\n",
        "  df.drop('mwra', axis=1)\n",
        "  return train_test_split(df, mwra, test_size=0.2)\n",
        "\n",
        "train_data, test_data, mwra_train, mwra_test = divide_df(merged_data[selected_attributes])"
      ],
      "metadata": {
        "id": "hXvy5R1mmKWV"
      },
      "execution_count": 39,
      "outputs": [],
      "id": "hXvy5R1mmKWV"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "-HzJ2voaXIQD"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('outlier_remover', OutlierRemover()),\n",
        "    ('power_transformer', PowerTransformerGroup()),\n",
        "    ('standard_scaler', StandardScalerGroup())\n",
        "]).fit(train_data, mwra_train)"
      ],
      "id": "-HzJ2voaXIQD"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}